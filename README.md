# Project Saiyan Augmented Reality (AR)  
### Real-Time Gesture-Controlled Super Saiyan Effects & Cinematic Environment

A high-performance, modular AR engine built in Python that simulates the power of a Super Saiyan. Features real-time gesture recognition, advanced particle physics, and cinematic environmental effects.

---

## ğŸš€ Overview

Project Saiyan AR is an immersive computer vision system that:

- **Super Saiyan Aura**: Real-time silhouette-hugging electric field (body lightning).
- **Cinematic Kamehameha**: Additive-blended energy sphere with fractal lightning and multi-layer bloom.
- **Continuous Burst**: Gesture-controlled energy blast that fires as long as your palms stay open.
- **Living Environment**: Parallax-scrolled backgrounds with flying rocks and dust debris.
- **Screen Shake (Tremors)**: Realistic camera vibration during energy charge and burst states.

---

## âœ¨ Key Features

- ğŸ” **Real-time Face & Hand Mesh**: 468 face landmarks and 21 hand landmarks per hand.
- âš¡ **Advanced Effects Engine**:
    - Recursive fractal lightning arcs and linear dodge blending.
    - Atmospheric heat haze and multi-radius Gaussian bloom.
- ğŸ– **Fist-to-Palm Control**: Clench fists to charge, relax palms to unleash a continuous energy burst.
- ğŸ” **Parallax Environment**: Multi-layer mountainous background that moves with 3D depth.
- ğŸª¨ **Physics-Based Debris**: Rocks and dust that "lift off" the ground as your power levels rise.
- ğŸ«¨ **Dynamic Camera Tremors**: Screen-shake intensity that scales with your energy level.

---

## ğŸ— System Architecture

```
Camera Input
â†“
Frame Processor (Face Mesh + Hands)
â†“
Gesture Engine (Fist-to-Palm + Proximity)
â†“
Effects Engine (Particles + Lightning + Bloom + Shake)
â†“
Background Engine (Segmentation + Parallax + Video)
â†“
Final Composite
```

---

## ğŸ›  Technology Stack

- Python 3.10+
- OpenCV
- MediaPipe
- NumPy

---

## ğŸ“‚ Project Structure (Core)

```
project-saiyan-ar/
â”‚
â”œâ”€â”€ main.py              # Main execution loop and orchestration
â”œâ”€â”€ camera.py            # Webcam abstraction
â”œâ”€â”€ face_tracker.py      # MediaPipe Face Mesh module
â”œâ”€â”€ hand_tracker.py      # MediaPipe Hands module
â”œâ”€â”€ gesture_engine.py    # Gesture state machine (Swipe/Fist/Palm)
â”œâ”€â”€ effects_engine.py    # Cinematic effects (Energy/Rocks/Shake)
â”œâ”€â”€ background_engine.py # Segmentation & Parallax logic
â”œâ”€â”€ utils.py             # Math and coordinate utilities
â”œâ”€â”€ requirements.txt     # Dependency list
â””â”€â”€ assets/              # Texture and video assets
```

---

## ğŸ§  Advanced Gesture Controls

### 1ï¸âƒ£ Super Saiyan Transformation
**Action**: Swipe your hand horizontally across your face.  
**Effect**: Toggles the Transformation mode. When enabled, your silhouette will glow with electrical arcs!

### 2ï¸âƒ£ Energy Charge (The Load)
**Action**: Bring both hands together and **clench your fists**.  
**Effect**: A golden energy ball pulses between your hands, rocks start lifting off the ground, and the screen begins to shake.

### 3ï¸âƒ£ Continuous Burst (Unleash)
**Action**: While hands are together, **relax your palms**.  
**Effect**: Fires a massive, continuous Kamehameha energy blast! Close your fists again to stop the blast.

---

## ğŸ–¥ Installation

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/Mohid-Abbas/RealTime-Gesture-Controlled-AR-Engine.git
cd RealTime-Gesture-Controlled-AR-Engine
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### â–¶ï¸ Running the Project

```bash
python main.py
```

Press q to exit.

---

## â€ğŸ’» Author

**Muhammad Mohid Abbas**  
Computer Vision & AI Enthusiast  

â­ If You Like This Project, give it a star!
